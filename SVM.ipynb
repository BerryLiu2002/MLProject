{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZAvYIvubfb7W","executionInfo":{"status":"ok","timestamp":1682444430490,"user_tz":240,"elapsed":19125,"user":{"displayName":"Thaison Le","userId":"15394235542894293790"}},"outputId":"aac2a7b5-6bd0-409d-a46f-67fd6baa4f5a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"aeQcS4SqfbWi"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"YlVpTQqAe-wl","executionInfo":{"status":"ok","timestamp":1682444462887,"user_tz":240,"elapsed":302,"user":{"displayName":"Thaison Le","userId":"15394235542894293790"}}},"outputs":[],"source":["# import required libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics, svm\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","\n","import itertools\n"]},{"cell_type":"markdown","metadata":{"id":"yG7MFSble-wn"},"source":["# Uploading Data"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YzLy_YrXe-wo","executionInfo":{"status":"ok","timestamp":1682444469496,"user_tz":240,"elapsed":6615,"user":{"displayName":"Thaison Le","userId":"15394235542894293790"}},"outputId":"aee250f4-afdd-49a0-c839-72ad995796d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/MLProj\n"]}],"source":["# sheep = np.load(r\"data\\full_numpy_bitmap_sheep.npy\")\n","# # print(sheep.shape)\n","# giraffe = np.load(r\"data\\full_numpy_bitmap_giraffe.npy\")\n","# # print(giraffe.shape)\n","# cat = np.load(r\"data\\full_numpy_bitmap_cat.npy\")\n","\n","# sheep = sheep[:1000]\n","# giraffe = giraffe[:1000]\n","# cat = cat[:1000]\n","\n","%cd /content/drive/MyDrive/MLProj/\n","\n","limit = 2000\n","\n","sheep = np.load(r\"full_numpy_bitmap_sheep.npy\")[0:limit]\n","giraffe = np.load(r\"full_numpy_bitmap_giraffe.npy\")[0:limit]\n","cat = np.load(r\"full_numpy_bitmap_cat.npy\")[0:limit]"]},{"cell_type":"markdown","metadata":{"id":"_36-ytwLe-wp"},"source":["Combining Data Sets and Splitting into Training, Validation, Testing Sets"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"QYpm1dcHe-wp","executionInfo":{"status":"ok","timestamp":1682444469497,"user_tz":240,"elapsed":7,"user":{"displayName":"Thaison Le","userId":"15394235542894293790"}}},"outputs":[],"source":["def combine_data(*args):\n","    X = np.zeros((0,784))\n","    Y = np.zeros((0,1))\n","    for i in range(len(args)):\n","        X = np.concatenate((X, args[i]))\n","        Y = np.concatenate((Y, np.ones((args[i].shape[0],1))*i))\n","    Y = Y.reshape(Y.shape[0])\n","    return X, Y\n","\n","def split_data(X, Y, split=(0.8,0.1,0.1)):\n","    # defaulting to an 80/10/10 train/test/val split\n","    train, test, val = split\n","    X_train, X_testval, Y_train, Y_testval = train_test_split(X, Y, test_size=test+val, random_state=42, shuffle=True)\n","    X_test, X_val, Y_test, Y_val = train_test_split(X_testval, Y_testval, test_size=val/(test+val), random_state=42, shuffle=True)\n","    return X_train, X_test, X_val, Y_train, Y_test, Y_val\n","\n","X, Y = combine_data(sheep, giraffe, cat)\n","X_train, X_test, X_val, Y_train, Y_test, Y_val = split_data(X, Y)"]},{"cell_type":"markdown","metadata":{"id":"MpBkhYrXe-wp"},"source":["Default SVM classifier function<br>\n","Will call to test each hyperparameter individually"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Z0MChS7Fe-wp","executionInfo":{"status":"ok","timestamp":1682444469497,"user_tz":240,"elapsed":7,"user":{"displayName":"Thaison Le","userId":"15394235542894293790"}}},"outputs":[],"source":["def create_classifier(X_train, Y_train, kernel=\"linear\", degree=1, C=1.0): # default values\n","    classifier = svm.SVC(kernel=kernel, degree=degree, C=C)\n","    classifier.fit(X_train, Y_train)\n","    return classifier"]},{"cell_type":"markdown","metadata":{"id":"odVAs4-ze-wq"},"source":["Accuracy"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"9--CKMDRe-wq","executionInfo":{"status":"ok","timestamp":1682444469497,"user_tz":240,"elapsed":6,"user":{"displayName":"Thaison Le","userId":"15394235542894293790"}}},"outputs":[],"source":["def accuracy(classifier, X_val, Y_val):\n","    return classifier.score(X_val, Y_val)\n","\n","# def plot_confusion_matrix(classifier, X_val, Y_val):"]},{"cell_type":"markdown","metadata":{"id":"vqtZHE5ce-wq"},"source":["Test for best normalization using default values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_UOjrl1e-wq"},"outputs":[],"source":["def test_norm(X_train, Y_train, X_val, Y_val, normalizations):\n","    data = {\"Normalization\": [], \"Accuracy\": []}\n","    for norm in normalizations:\n","        if norm is not None:\n","            scaler = norm\n","            X_train_norm = scaler.fit_transform(X_train)\n","            X_val_norm = scaler.transform(X_val)\n","        else:\n","            X_train_norm = X_train\n","            X_val_norm = X_val\n","        classifier = create_classifier(X_train_norm, Y_train)\n","        acc = accuracy(classifier, X_val_norm, Y_val)\n","        data[\"Normalization\"].append(norm)\n","        data[\"Accuracy\"].append(acc)\n","    return pd.DataFrame(data)\n","\n","# normalizations\n","normalizations = [None, StandardScaler(), MinMaxScaler()]\n","df = test_norm(X_train, Y_train, X_val, Y_val, normalizations)\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"czEokgFYe-wr"},"source":["Testing C Values (Kernels: Linear, Polynomial Deg: 2,3,4, RBF)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y59CB5oie-wr"},"outputs":[],"source":["def classify_and_df(X_tr, Y_tr, X_val, Y_val, kernel, C_vals, degree=1):\n","    data = {\"C\": [], \"Accuracy\": []}\n","    for C_val in C_vals:\n","        classifier = create_classifier(X_tr, Y_tr, kernel=kernel, degree=degree, C=C_val)\n","        acc = accuracy(classifier, X_val, Y_val)\n","        data[\"C\"].append(C_val)\n","        data[\"Accuracy\"].append(acc)\n","    return pd.DataFrame.from_dict(data)\n","\n","def test_kern_deg(X_tr, Y_tr, X_val, Y_val, kernels, C_vals, degrees, scaler=None):\n","    # scale data\n","    X_train_scaled = scaler.fit_transform(X_tr) if scaler else X_tr\n","    X_val_scaled = scaler.transform(X_val) if scaler else X_val\n","    # for each kernel type, test different C values and return dataframe storing C_vals and accuracy data\n","    for kernel in kernels:\n","        # if kernel is polynomial, test different degrees\n","        if kernel == \"poly\":\n","            for degree in degrees:\n","                dataframe = classify_and_df(X_train_scaled, Y_train, X_val_scaled, Y_val, kernel, C_vals, degree)\n","                yield (kernel, degree, dataframe)\n","        else:\n","            dataframe = classify_and_df(X_train_scaled, Y_train, X_val_scaled, Y_val, kernel, C_vals)\n","            yield (kernel, 1, dataframe)\n","\n","C_vals = [0.0000001, 0.00001, 0.001, 0.01, 0.1, 1, 10, 100, 10000, 1000000]\n","kernels = [\"linear\", \"poly\", \"rbf\"]\n","degrees = [2, 3, 4]\n","with open(\"SVM_results.csv\", \"w\") as f:\n","    for kernel, degree, df in test_kern_deg(X_train, Y_train, X_val, Y_val, kernels, C_vals, degrees, scaler=StandardScaler()):\n","        f.write(f\"{kernel}_{degree}\\n\")\n","        print(df)\n","        df.to_csv(f, sep='\\t', encoding='utf-8', index=False, lineterminator='\\n', columns=[\"C\", \"Accuracy\"])\n","        f.write('\\n')"]},{"cell_type":"markdown","metadata":{"id":"GMgbZtdze-ws"},"source":["Test Optimal Hyperparameters on Test Set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8bzx7y7fe-ws"},"outputs":[],"source":["def train_and_return_confusion_matrix(X_tr, Y_tr, X_test, Y_test, kernel, C, degree=1, scaler=None):\n","    # scale data\n","    X_train_scaled = scaler.fit_transform(X_tr) if scaler else X_tr\n","    X_test_scaled = scaler.transform(X_test) if scaler else X_test\n","    # train classifier\n","    classifier = create_classifier(X_train_scaled, Y_tr, kernel=kernel, degree=degree, C=C)\n","    # return confusion matrix\n","    print(accuracy(classifier, X_test_scaled, Y_test))\n","    return metrics.confusion_matrix(Y_test, classifier.predict(X_test_scaled))\n","\n","def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","    print(cm)\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","cm = train_and_return_confusion_matrix(X_train, Y_train, X_test, Y_test, kernel=\"poly\", C=10, degree = 3, scaler=StandardScaler())\n","plot_confusion_matrix(cm, [\"Sheep\", \"Giraffe\", \"Cat\"], normalize=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJIqNqWke-ws"},"outputs":[],"source":["# def test_kern_deg_reg_none(kernels, degrees, C_vals):\n","#     data = {\"Kernel\": [], \"Degree\": [], \"C\": [], \"Accuracy\": []}\n","#     for kernel in kernels:\n","#         for degree in degrees:\n","#             for C in C_vals:\n","#                 classifier = create_classifier(X_train, Y_train, kernel=kernel, degree=degree, C=C)\n","#                 acc = accuracy(classifier, X_val, Y_val)\n","#                 data[\"C\"].append(C)\n","#                 data[\"Kernel\"].append(kernel)\n","#                 data[\"Degree\"].append(degree)\n","#                 data[\"Accuracy\"].append(acc)\n","#     df = pd.DataFrame(data)\n","#     return df\n","\n","# C_vals = [0.01, 0.1, 1, 10]\n","# kernels = [\"linear\", \"poly\", \"rbf\"]\n","# degrees = [1, 2, 3, 4, 5]\n","# df = test_kern_deg_reg_none(kernels, degrees, C_vals)\n","# print(df)"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":4,"colab":{"provenance":[],"machine_shape":"hm"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}